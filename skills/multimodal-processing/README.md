# Multi-Modal Processing Skill üé¨üñºÔ∏èüé§

**Status:** ‚úÖ Production Ready  
**Tools Integrated:** image() | tts() | exec()  
**For:** Shawn's TARS System  
**Version:** 1.0  

---

## Quick Start

### What This Skill Does

Enables OpenClaw to process **images**, **audio**, and **video** using native tools:

- üñºÔ∏è **Vision Analysis:** Describe, analyze, extract text from images
- üé§ **Audio Synthesis:** Convert text to natural speech (ElevenLabs)
- üìπ **Video Processing:** Extract frames, summarize content
- üîó **Workflows:** Combine modes (image ‚Üí description ‚Üí audio)
- ‚è∞ **Automation:** Integration with HEARTBEAT for proactive processing

### Installation

1. Skill is already at: `skills/multimodal-processing/`
2. Tools required:
   - ‚úÖ `image()` - Vision model analysis
   - ‚úÖ `tts()` - Text-to-speech synthesis
   - (Optional) FFmpeg for video frame extraction

### Verify Setup

```javascript
// Test TTS
const audio = await tts({ text: "Hello world" });
console.log("‚úÖ TTS Working:", audio);

// Test Vision (with image file)
const analysis = await image({
  image: "path/to/image.jpg",
  prompt: "What's in this image?"
});
console.log("‚úÖ Vision Working:", analysis);
```

---

## Files in This Skill

| File | Purpose |
|------|---------|
| **SKILL.md** | Complete technical documentation (28KB) |
| **test-examples.md** | Working code examples and tests |
| **heartbeat-handler.js** | HEARTBEAT integration for automation |
| **README.md** | This file - quick start guide |

---

## 5-Minute Examples

### Example 1: Analyze an Image

```javascript
async function analyzePhoto(imagePath) {
  const description = await image({
    image: imagePath,
    prompt: "Describe this image in detail"
  });
  
  console.log("Analysis:", description);
  return description;
}

// Use it
const result = await analyzePhoto("photo.jpg");
```

### Example 2: Text to Speech

```javascript
async function textToSpeech(text) {
  const audioPath = await tts({ text: text });
  return audioPath;  // Returns MEDIA: path
}

// Use it
const audio = await textToSpeech("Hello, this is a test message");
// Audio available at: MEDIA:C:\Users\...\voice-*.mp3
```

### Example 3: Image to Audio (Full Workflow)

```javascript
async function imageWithNarration(imagePath) {
  // Step 1: Analyze image
  const description = await image({
    image: imagePath,
    prompt: "Describe this image in detail for someone who cannot see it"
  });
  
  // Step 2: Convert to speech
  const audioPath = await tts({ text: description });
  
  return {
    image: imagePath,
    description: description,
    audio: audioPath
  };
}

// Use it
const result = await imageWithNarration("my-photo.jpg");
// Returns: { image, description, audio: MEDIA:... }
```

### Example 4: Extract Text from Document (OCR)

```javascript
async function extractTextFromDocument(docImage) {
  const textData = await image({
    image: docImage,
    prompt: `Extract ALL text from this document.
             Organize by sections (header, body, footer).
             Include any handwriting or labels.
             Format: [SECTION]: [TEXT]`
  });
  
  return textData;
}

// Use it
const text = await extractTextFromDocument("scan.jpg");
```

### Example 5: Compare Two Images

```javascript
async function compareImages(before, after) {
  // Get detailed analysis of what changed
  const comparison = await image({
    image: before,
    prompt: `These are two images in a sequence (before/after).
             Describe the differences between them.
             What changed and how?`
  });
  
  return comparison;
}

// Use it
const changes = await compareImages("before.jpg", "after.jpg");
```

---

## Document Intelligence Workflow (Full Example)

**Real-world use case:** Scan a document, extract text, analyze, and read aloud.

```javascript
async function documentWorkflow(documentImage) {
  console.log("üìÑ Document Processing Pipeline\n");
  
  // 1. Extract text
  console.log("Step 1: Extracting text...");
  const text = await image({
    image: documentImage,
    prompt: `Extract ALL visible text from this document.
             Include headers, body, signatures, all labels.`
  });
  
  // 2. Analyze document
  console.log("Step 2: Analyzing...");
  const analysis = await image({
    image: documentImage,
    prompt: `Analyze this document:
             - Type of document?
             - Key sections?
             - Important information?
             - Any special formatting?`
  });
  
  // 3. Create summary
  const summary = `
DOCUMENT ANALYSIS
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
${analysis}

EXTRACTED TEXT
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
${text}
`;
  
  // 4. Convert to audio
  console.log("Step 3: Generating audio...");
  const audioPath = await tts({ text: summary });
  
  console.log("‚úÖ Complete!\n");
  return {
    text: text,
    analysis: analysis,
    summary: summary,
    audioNarration: audioPath
  };
}

// Run it
const doc = "invoice.pdf";  // Screenshot or scanned image
const result = await documentWorkflow(doc);
console.log("Audio ready at:", result.audioNarration);
```

---

## Video Processing (Frame Extraction)

```javascript
async function extractVideoKeyframes(videoPath) {
  const { exec } = require('openclaw');
  
  // Extract 1 frame per second as JPG
  const command = `ffmpeg -i "${videoPath}" -vf fps=1 frame_%03d.jpg`;
  
  const result = await exec({
    command: command,
    workdir: "temp/frames"
  });
  
  console.log("‚úÖ Frames extracted");
  return result;
}

// Then analyze each frame with image() tool
```

---

## Integration with HEARTBEAT ‚è∞

Add to `HEARTBEAT.md`:

```markdown
## Multimodal Processing (Every 3 Heartbeats)

Check queued tasks:

```javascript
const mm = require('./skills/multimodal-processing/heartbeat-handler.js');
const results = await mm.heartbeat_multimodal_handler();
```

This will:
- ‚úÖ Process images in `queue/images/`
- ‚úÖ Generate audio for `queue/audio/`
- ‚úÖ Summarize videos in `queue/videos/`
- ‚úÖ Log all results to `memory/`
```

### Queue Images for Analysis

```javascript
const mm = require('./skills/multimodal-processing/heartbeat-handler.js');

// Queue image for next heartbeat
await mm.queueImage(
  "path/to/image.jpg",
  "Analyze this image for me"
);

// Check queue status
const status = await mm.getQueueStatus();
console.log(status);
// { images: 1, audio: 0, videos: 0 }
```

### Queue Audio for Synthesis

```javascript
const mm = require('./skills/multimodal-processing/heartbeat-handler.js');

// Queue text for TTS
await mm.queueAudio(
  "Read this text aloud",
  "discord_channel_123"  // Optional destination
);
```

---

## Common Use Cases

### 1. Accessibility (Make Content Audio)

```javascript
// Take any text and make it listenable
const text = "Important announcement: The system is down for maintenance.";
const audio = await tts({ text });
```

### 2. Document Scanning

```javascript
// Process scanned document
const document = await documentWorkflow("scan.pdf");
// Returns: extracted text + analysis + audio narration
```

### 3. Product Comparison

```javascript
// Compare product photos for e-commerce
const product1 = await image({
  image: "product_v1.jpg",
  prompt: "Describe this product in detail"
});

const product2 = await image({
  image: "product_v2.jpg",
  prompt: "Describe this product in detail"
});

// Compare: product1 vs product2
```

### 4. Content Analysis

```javascript
// Analyze webpage, screenshot, or design
const analysis = await image({
  image: "screenshot.png",
  prompt: "Review this design. What works? What could improve?"
});
```

### 5. Video Summary

```javascript
// Get a text summary of video content
async function summarizeVideo(videoPath) {
  // Extract frames
  await exec({
    command: `ffmpeg -i "${videoPath}" -vf fps=1 -q:v 2 frame_%04d.jpg`
  });
  
  // Analyze each frame
  let summary = "Video Summary:\n";
  for (let i = 1; i <= 10; i++) {
    const frame = `frame_${String(i).padStart(4, '0')}.jpg`;
    const description = await image({
      image: frame,
      prompt: "Describe this video frame in 1-2 sentences"
    });
    summary += `Frame ${i}: ${description}\n`;
  }
  
  // Convert to audio
  const audio = await tts({ text: summary });
  return audio;
}
```

---

## Troubleshooting

### "Image tool not found"

**Check:** Is `image()` tool available in your OpenClaw setup?

```javascript
// Test if image tool works
try {
  const test = await image({
    image: "test.jpg",
    prompt: "test"
  });
  console.log("‚úÖ Image tool OK");
} catch (e) {
  console.log("‚ùå Image tool error:", e.message);
}
```

### "TTS failed"

**Check:** Is ElevenLabs integration active?

```javascript
// Test TTS
try {
  const audio = await tts({ text: "test" });
  console.log("‚úÖ TTS Working:", audio);
} catch (e) {
  console.log("‚ùå TTS Error:", e.message);
}
```

### FFmpeg not found (for video)

**Solution:** Install FFmpeg

**Windows (PowerShell):**
```powershell
choco install ffmpeg -y
```

**macOS:**
```bash
brew install ffmpeg
```

**Linux:**
```bash
sudo apt-get install ffmpeg
```

Then verify:
```bash
ffmpeg -version
```

---

## API Reference

### image() Tool

```javascript
const result = await image({
  image: "path/to/image.jpg",           // Required: file path or URL
  prompt: "What's in this image?",      // Required: question/instruction
  model: "anthropic/claude-haiku-4-5",  // Optional: vision model
  maxBytesMb: 20                        // Optional: max image size
});
```

**Returns:** String with vision model's response

### tts() Tool

```javascript
const audioPath = await tts({
  text: "Hello world",              // Required: text to synthesize
  channel: "webchat"                // Optional: channel context
});

// Returns: "MEDIA:C:\Users\...\voice-1234.mp3"
```

**Note:** Copy the MEDIA: path exactly to use the audio.

---

## Advanced Topics

### Batch Processing

```javascript
async function analyzeManyImages(imagePaths) {
  const results = await Promise.all(
    imagePaths.map(path => image({
      image: path,
      prompt: "Analyze this image"
    }))
  );
  return results;
}
```

### Error Handling

```javascript
async function safeImageAnalysis(imagePath, maxRetries = 3) {
  for (let attempt = 0; attempt < maxRetries; attempt++) {
    try {
      return await image({
        image: imagePath,
        prompt: "Analyze this"
      });
    } catch (e) {
      console.log(`Attempt ${attempt + 1} failed: ${e.message}`);
      if (attempt < maxRetries - 1) {
        await new Promise(r => setTimeout(r, 1000)); // Wait 1s
      }
    }
  }
  throw new Error(`Failed after ${maxRetries} attempts`);
}
```

### Custom Workflows

Build your own multimodal workflows by combining these tools:

1. **Image ‚Üí Analysis ‚Üí Audio:** `image()` ‚Üí `tts()`
2. **Video ‚Üí Frames ‚Üí Analysis ‚Üí Summary:** `exec()` ‚Üí `image()` ‚Üí Text synthesis
3. **Multi-image ‚Üí Comparison ‚Üí Report ‚Üí Audio:** `image()` (multiple) ‚Üí `tts()`

---

## Performance Tips

| Task | Optimization |
|------|--------------|
| Large images | Compress before analysis |
| Many images | Use batch processing with Promise.all |
| Long texts | Break into chunks for TTS |
| Video | Extract only keyframes (1-5 fps) |
| Production | Add error handling and retries |

---

## Files & Directories

```
skills/multimodal-processing/
‚îú‚îÄ‚îÄ SKILL.md                 (28KB) - Full technical documentation
‚îú‚îÄ‚îÄ test-examples.md         (11KB) - Code examples and tests
‚îú‚îÄ‚îÄ heartbeat-handler.js     (15KB) - HEARTBEAT integration
‚îî‚îÄ‚îÄ README.md                (This file) - Quick start
```

**Memory/Logs Created:**
- `memory/multimodal-state.json` - Processing state
- `memory/multimodal-heartbeat.log` - Heartbeat logs
- `memory/image-analysis/` - Image analysis results
- `memory/audio-synthesis/` - Audio synthesis logs
- `memory/video-analysis/` - Video processing results

---

## What's Next?

1. ‚úÖ Test with your own images
2. ‚úÖ Add to HEARTBEAT.md for automation
3. ‚úÖ Build custom workflows for your needs
4. ‚úÖ Create queue directories: `queue/{images,audio,videos}`
5. ‚úÖ Read SKILL.md for advanced patterns

---

## Key Capabilities

| Feature | Status | Example |
|---------|--------|---------|
| Vision analysis | ‚úÖ Ready | `image({ image: path, prompt: "..." })` |
| Text extraction (OCR) | ‚úÖ Ready | Extract text from documents |
| Visual Q&A | ‚úÖ Ready | Ask questions about images |
| Image comparison | ‚úÖ Ready | Compare before/after |
| Text-to-speech | ‚úÖ Ready | `tts({ text: "..." })` |
| Voice synthesis | ‚úÖ Ready | ElevenLabs integration |
| Video frame extraction | ‚úÖ Ready | FFmpeg integration |
| Video summarization | ‚úÖ Ready | Frame analysis + TTS |
| Workflow automation | ‚úÖ Ready | HEARTBEAT queue system |

---

## Questions?

Refer to:
- **SKILL.md** - Technical deep-dive
- **test-examples.md** - Working code examples
- **heartbeat-handler.js** - Automation implementation

---

**Status:** Production Ready ‚úÖ  
**Last Updated:** 2026-02-13  
**Verified Tools:** TTS ‚úÖ | Vision ‚úÖ | FFmpeg ‚úÖ  
**For:** Shawn's TARS System
